- 要件殴り書き
  - 複数のネットワークカメラで撮影したリアルタイム映像をAIで画像解析して手の状態（ジェスチャー）を判定する画像解析AIシステムを開発する
  - 映像の取得はRTPS通信にて行う
  - ジェスチャーの種類は問わない
  - カメラの台数は1台だけでも動作可能
  - 判定するAIはPyTorchの事前学習済みモデルを利用するが、OpenVINO IR変換することでCPU/iGPUに特化させること
  - GUIも実装して解析結果をリアルタイムで描画し表示できるようにすること
  - multiprocessingを使って複数カメラの映像解析を並列で処理すること
  - 設定で各種パラメータを変更できるようにすること
  - 複数カメラからのリアルタイム映像取得だけでなく、複数カメラの録画／動画保存やその動画の読み込み機能も実装すること
  - メイン実行時は外部ネットワークには繋がらないようにすること（事前学習済みPytorchモデルをOpenVINO IR変換して保存するスクリプトなど、事前準備として別途実行する必要のあるスクリプトについては、ProgramName/toolsディレクトリにスクリプトを作成し格納すること）
  - データベースやクラウドへのアクセスはしないこと（クラウド利用でモデルを自動更新する機能の実装は今のところやる予定はない）